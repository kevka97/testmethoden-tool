import streamlit as st
import pandas as pd
from io import BytesIO
import datetime

# Audi-Logo einf√ºgen (Logo-Datei muss im selben Ordner liegen)
st.image("audi_logo.png", width=150)

# Dark Mode Toggle (klein & sichtbar in der Kopfzeile)
col1, col2 = st.columns([6, 1])  # Hauptbereich + kleine Spalte f√ºr den Toggle
with col2:
    dark_mode = st.toggle("üåó")

# Falls test_recommendations noch nicht existiert, erstelle eine leere Liste davor:
test_recommendations = []  # Liste f√ºr den Excel-Export

# Styling f√ºr Dark & Light Mode
if dark_mode:
    st.markdown(
        """
        <style>
        body, .stApp {
            background-color: #0e1117;
            color: white;
        }
        </style>
        """,
        unsafe_allow_html=True
    )
else:
    st.markdown(
        """
        <style>
        body, .stApp {
            background-color: white;
            color: black;
        }
        </style>
        """,
        unsafe_allow_html=True
    )

# Titel und Beschreibung
st.markdown("<div class='title'>Testmethoden-Empfehlungs-Tool</div>", unsafe_allow_html=True)
st.markdown("<div class='subtitle'>Bestimmen Sie geeignete Testmethoden mit relevanten Tools und Best Practices.</div>", unsafe_allow_html=True)

# Eingabeformular f√ºr die Klassifikation
st.header("Systemklassifikation")
with st.form("classification_form"):
    system_name = st.text_input("Name des Systems/Services", value="")

    system_description = st.text_area(
        "Kurzbeschreibung ",
        value="",
        help="Beschreiben Sie das System oder den Service kurz und pr√§gnant."
    )

    system_type = st.selectbox(
        "Systemtyp ",
        ["Bitte ausw√§hlen", "Neuentwicklung", "Migration", "Update"],
        index=0,
        help="W√§hlen Sie aus, ob das System neu entwickelt wird, eine Migration erfolgt oder ein Update durchgef√ºhrt wird."
    )

    environment = st.selectbox(
        "Betriebsumgebung ",
        ["Bitte ausw√§hlen", "On-Premise", "Cloud"],
        index=0,
        help="On-Premise bedeutet, dass das System lokal gehostet wird. Cloud bedeutet, dass das System in einer Cloud-Umgebung betrieben wird."
    )

    real_time_processing = st.selectbox(
        "Echtzeitverarbeitung erforderlich? ",
        ["Bitte ausw√§hlen", "Ja", "Nein"],
        index=0,
        help="Ben√∂tigt Ihr System eine sofortige Verarbeitung von Daten, ohne Verz√∂gerung?"
    )

    data_sensitivity = st.selectbox(
        "Datenart ",
        ["Bitte ausw√§hlen", "Technische Logdaten", "Personenbezogene/Firmenkritische Daten"],
        index=0,
        help="Handelt es sich um einfache technische Logs oder um personenbezogene bzw. firmenkritische Daten, die besonders gesch√ºtzt werden m√ºssen?"
    )

    regulatory_requirements = st.selectbox(
        "Regulatorische Vorgaben? ",
        ["Bitte ausw√§hlen", "Ja", "Nein"],
        index=0,
        help="Gibt es gesetzliche oder branchenspezifische Vorschriften (z. B. DSGVO, ISO 27001), die Ihr System einhalten muss?"
    )

    availability = st.selectbox(
        "24/7 Verf√ºgbarkeit erforderlich? ",
        ["Bitte ausw√§hlen", "Ja", "Nein"],
        index=0,
        help="Muss Ihr System rund um die Uhr verf√ºgbar sein, ohne geplante Ausf√§lle?"
    )

    high_api_dependence = st.selectbox(
        "Hohe API-Abh√§ngigkeit? ",
        ["Bitte ausw√§hlen", "Ja", "Nein"],
        index=0,
        help="Ist Ihr System stark auf externe oder interne APIs angewiesen?"
    )

    deployment_frequency = st.selectbox(
        "Deployment-Frequenz ",
        ["Bitte ausw√§hlen", "Monatlich", "W√∂chentlich", "T√§glich"],
        index=0,
        help="Wie oft werden neue Versionen des Systems bereitgestellt? Dies beeinflusst die Notwendigkeit f√ºr automatisierte Tests."
    )

    submit_button = st.form_submit_button("Empfohlene Testmethoden anzeigen")

# Funktion zur strukturierten Anzeige der Testmethoden mit vollst√§ndigen Erkl√§rungen
def display_test_method(name, description, problems, best_practices, tools):
    """ Formatiert die Testmethode mit ausf√ºhrlicher Erkl√§rung, Problemen und Best Practices """
    st.markdown(f"### {name}")
    st.write(f"**Beschreibung:** {description}")

    st.write("H√§ufige Probleme:")
    for problem in problems:
        st.markdown(f"- {problem}")

    st.write("Best Practices:")
    for practice in best_practices:
        st.markdown(f"- {practice}")

    st.write("Eingesetzte Tools:")
    for tool_category, tool_list in tools.items():
        st.markdown(f"- **{tool_category}**: {', '.join(tool_list)}")

    st.markdown("---")

    # Speichert die Empfehlungen f√ºr den Export in Excel
    test_recommendations.append({
        "Testmethode": name,
        "Beschreibung": description,
        "H√§ufige Probleme": "\n".join(problems),
        "Best Practices": "\n".join(best_practices),
        "Eingesetzte Tools": "\n".join([f"{cat}: {', '.join(lst)}" for cat, lst in tools.items()])
    })

# Verarbeitung der Eingaben und Ausgabe von Testmethoden
if submit_button:
    if "Bitte ausw√§hlen" in [system_type, environment, real_time_processing, data_sensitivity, regulatory_requirements,
                             availability, high_api_dependence, deployment_frequency]:
        st.warning("Bitte f√ºllen Sie alle Felder aus, bevor Sie Testmethoden anzeigen.")
    else:
        st.subheader("Empfohlene Testmethoden f√ºr Ihr System")
        st.write(f"**System-/Service-Name:** {system_name}")
        st.write(f"**Beschreibung:** {system_description}")

        # F√ºge hier den Trennstrich hinzu, bevor die Empfehlungen starten
        st.markdown("---")

        # SYSTEMTYP
        if system_type == "Migration":
            display_test_method(
                "Datenmigrationstests",
                "Datenmigrationstests stellen sicher, dass alle Daten aus dem Quellsystem vollst√§ndig, "
                "korrekt und ohne Datenverlust oder -korruption in das Zielsystem √ºbertragen werden. "
                "Dies ist besonders wichtig, um die Datenintegrit√§t und Konsistenz nach der Migration zu gew√§hrleisten.",
                ["Datenverluste oder unvollst√§ndige √úbertragungen, die durch fehlerhafte Extraktions-, Transformations- oder Ladeprozesse (ETL) entstehen k√∂nnen.",
                "Formatierungsfehler oder inkonsistente Daten aufgrund unterschiedlicher Datenstrukturen oder inkompatibler Zeichens√§tze zwischen Quell- und Zielsystem.",
                "Verlust von Beziehungen oder Abh√§ngigkeiten zwischen Datens√§tzen, insbesondere bei relationalen Datenbanken.",
                "Performanzprobleme w√§hrend der Migration, die zu Zeit√ºberschreitungen oder Systemausf√§llen f√ºhren k√∂nnen."],
                ["Vergleich von Quell- und Zieldaten durch Hash-Pr√ºfsummen oder Row-Count-Validierungen zur Identifikation von Differenzen.",
                "Einsatz automatisierter Validierungswerkzeuge zur √úberpr√ºfung von Datenintegrit√§t und -konsistenz.",
                "Stichprobenbasierte manuelle Pr√ºfung kritischer Datens√§tze zur Sicherstellung der erwarteten Datenqualit√§t.",
                "Einsatz von Testmigrationen in einer isolierten Umgebung, um potenzielle Probleme vor der Produktivmigration zu identifizieren.",
                "Durchf√ºhrung von Performanztests zur Bewertung der Migrationseffizienz und zur Identifikation von Engp√§ssen."],
                {"Migrationstools": ["Talend", "dbForge Studio"]}
            )

        if system_type == "Update":
            display_test_method(
                "Regressionstests",
                "Regressionstests stellen sicher, dass nach einer √Ñnderung oder einem Update bestehende "
                "Funktionen weiterhin korrekt arbeiten, ohne dass unerwartete Fehler auftreten. "
                "Diese Tests sind besonders wichtig in agilen Entwicklungsprozessen mit h√§ufigen Releases, um die "
                "Stabilit√§t der Anwendung sicherzustellen.",
                ["Funktionalit√§ten brechen nach Updates, insbesondere wenn Abh√§ngigkeiten zwischen Modulen nicht ausreichend getestet wurden.",
                "Performance-Probleme durch neue √Ñnderungen, die unerwartete Lastspitzen oder Engp√§sse verursachen.",
                "Nicht-erfasste Seiteneffekte in bestehenden Workflows, die zu unerwartetem Verhalten f√ºhren k√∂nnen.",
                "Fehlende Abdeckung von kritischen Gesch√§ftsprozessen, was zu Produktionsausf√§llen f√ºhren kann."],
                ["Automatisierte Regressionstests in den CI/CD-Prozess integrieren, um fr√ºhzeitige Fehlererkennung zu erm√∂glichen.",
                 "Schl√ºssel-Features priorisieren und sicherstellen, dass Kernfunktionalit√§ten nach jedem Update getestet werden.",
                 "Smoke-Tests als ersten Schritt ausf√ºhren, um grundlegende Funktionen schnell zu √ºberpr√ºfen.",
                 "Differenzielle Tests verwenden, um nur die direkt betroffenen Bereiche effizient zu testen.",
                 "Regelm√§√üige Code-Reviews und statische Code-Analysen erg√§nzend zu Regressionstests einsetzen."],
                {"Regressionstests": ["Selenium", "Azure DevOps Pipelines"]}
            )

        # ECHTZEITVERARBEITUNG
        if real_time_processing == "Ja" and environment == "Cloud":
            display_test_method(
                "Disaster Recovery Tests",
                "Disaster Recovery Tests √ºberpr√ºfen, ob ein System nach unerwarteten Ausf√§llen schnell und "
                "zuverl√§ssig wiederhergestellt werden kann.Dies ist besonders im Cloud-Umfeld relevant, wo hochverf√ºgbare "
                "und skalierbare Architekturen genutzt werden, aber dennoch Ausf√§lle durch Fehlkonfigurationen, Datenverlust "
                "oder externe Angriffe auftreten k√∂nnen.",
                ["Datenverluste oder lange Wiederherstellungszeiten durch unzureichende oder fehlerhafte Backup- und Wiederherstellungsstrategien.",
                "Fehlendes automatisiertes Backup, wodurch Daten in Echtzeit verloren gehen k√∂nnen, insbesondere bei Datenbank-Clustern oder Streaming-Diensten.",
                "Netzwerk- oder Infrastruktur-Ausf√§lle in Cloud-Umgebungen, die zu Systemausf√§llen oder Latenzproblemen f√ºhren.",
                "Unzureichende Failover-Mechanismen, die nicht automatisiert ausgel√∂st werden und manuelle Eingriffe erfordern."],
                ["Regelm√§√üige Backup- & Restore-Tests durchf√ºhren, um die Integrit√§t und Konsistenz der Backups zu gew√§hrleisten.",
                "Disaster-Recovery-Pl√§ne dokumentieren und automatisierte Failover-Szenarien testen.",
                "Multi-Region-Backups und Geo-Redundanz in der Cloud nutzen, um hohe Verf√ºgbarkeit sicherzustellen.",
                "Automatisierte Recovery-Prozesse in Cloud-Umgebungen implementieren, um Systemausf√§lle auf ein Minimum zu reduzieren.",
                "Datenbank-Replikation und Point-in-Time Recovery (PITR) aktiv nutzen, um verlorene Daten exakt wiederherstellen zu k√∂nnen."],
                {"Backup-Tools": ["Veeam", "Commvault"],
                        "AWS-Tools": ["AWS Backup", "AWS Elastic Disaster Recovery"]}
            )

        # DATENSENSIBILIT√ÑT
        if data_sensitivity == "Personenbezogene/Firmenkritische Daten":
            display_test_method(
                "Sicherheitstests",
                "Sicherheitstests sind essenziell f√ºr den Schutz sensibler Daten vor unbefugtem Zugriff, Manipulation oder Datenlecks. "
                "Besonders personenbezogene und firmenkritische Daten m√ºssen vor externen Angriffen sowie internen Sicherheitsrisiken gesch√ºtzt werden. "
                "Diese Tests helfen, Schwachstellen fr√ºhzeitig zu erkennen und Sicherheitsma√ünahmen effektiv zu implementieren.",
                ["Sicherheitstests sind essenziell f√ºr den Schutz sensibler Daten vor unbefugtem Zugriff, Manipulation oder Datenlecks. "
                "Besonders personenbezogene und firmenkritische Daten m√ºssen vor externen Angriffen sowie internen Sicherheitsrisiken gesch√ºtzt werden. "
                "Diese Tests helfen, Schwachstellen fr√ºhzeitig zu erkennen und Sicherheitsma√ünahmen effektiv zu implementieren.",],
                ["Regelm√§√üige Penetrationstests durchf√ºhren, um Sicherheitsl√ºcken fr√ºhzeitig zu identifizieren.",
                "Security-Scans in den CI/CD-Prozess einbinden, um Sicherheitsprobleme direkt in der Entwicklung zu erkennen.",
                "Strenge Zugriffskontrollen nach dem Least-Privilege-Prinzip umsetzen.",
                "Ende-zu-Ende-Verschl√ºsselung f√ºr gespeicherte und √ºbertragene Daten nutzen.",
                "Monitoring und Logging von sicherheitskritischen Ereignissen aktiv betreiben."],
                {"Security-Tools": ["OWASP ZAP", "Burp Suite", "AWS Security Hub"]}
            )

        # REGULATORISCHE VORGABEN
        if regulatory_requirements == "Ja":
            display_test_method(
                "Compliance-Sicherheitstests",
                "Compliance-Sicherheitstests √ºberpr√ºfen, ob Systeme und Prozesse gesetzliche und "
                "branchenspezifische Vorgaben einhalten. Dies ist besonders relevant f√ºr Datenschutzrichtlinien wie die "
                "DSGVO oder ISO 27001, die strenge Anforderungen an Datenverarbeitung, Sicherheit und Dokumentation stellen.",
                [ "Nicht-Einhaltung von Datenschutzrichtlinien, die zu rechtlichen Konsequenzen und hohen Strafen f√ºhren k√∂nnen.",
                "Fehlende Dokumentation von Sicherheits- und Datenschutzma√ünahmen, was eine Nachverfolgbarkeit und Auditierbarkeit erschwert.",
                "Unzureichende Zugriffskontrollen oder Verschl√ºsselungsma√ünahmen f√ºr sch√ºtzenswerte Daten.",
                "Unklare Verantwortlichkeiten in der Organisation, was zu Sicherheitsl√ºcken f√ºhren kann."],
                [ "Nicht-Einhaltung von Datenschutzrichtlinien, die zu rechtlichen Konsequenzen und hohen Strafen f√ºhren k√∂nnen.",
                "Fehlende Dokumentation von Sicherheits- und Datenschutzma√ünahmen, was eine Nachverfolgbarkeit und Auditierbarkeit erschwert.",
                "Unzureichende Zugriffskontrollen oder Verschl√ºsselungsma√ünahmen f√ºr sch√ºtzenswerte Daten.",
                "Unklare Verantwortlichkeiten in der Organisation, was zu Sicherheitsl√ºcken f√ºhren kann."],
                {"Compliance-Tools": ["OneTrust", "AWS Artifact"]}
            )

        # VERF√úGBARKEIT
        if availability == "Ja" and environment == "Cloud":
            display_test_method(
                "Cloud Performance-Tests",
                "Cloud Performance-Tests bewerten, ob eine Anwendung in einer Cloud-Umgebung unter variabler Last effizient skaliert "
                "und performant bleibt. Sie sind essenziell, um Engp√§sse zu identifizieren, die Stabilit√§t bei Lastspitzen zu sichern "
                "und die Effizienz von Auto-Scaling-Mechanismen zu √ºberpr√ºfen.",
                ["Lange Antwortzeiten unter Last, insbesondere bei pl√∂tzlichen oder hohen Lastspitzen.",
                "Unzureichende Skalierungsmechanismen, die nicht schnell genug zus√§tzliche Ressourcen bereitstellen.",
                "Kostenexplosion durch ineffiziente Skalierungsregeln oder fehlerhafte Ressourcen-Zuweisung.",
                "Datenbank- oder Netzwerkengp√§sse, die zu unerwarteten Performance-Problemen f√ºhren.",
                "Mangelnde Observability, sodass Performance-Engp√§sse schwer zu identifizieren sind."],
                ["Lasttests mit realistischen Szenarien und Workloads durchf√ºhren, um Engp√§sse fr√ºhzeitig zu identifizieren.",
                "Auto-Scaling-Mechanismen aktiv nutzen und regelm√§√üig testen, um sicherzustellen, dass sie korrekt greifen.",
                "Monitoring und Observability mit Cloud-nativen Tools implementieren, um Performance-Flaschenh√§lse schnell zu erkennen.",
                "Performance-Optimierung durch Caching-Strategien, asynchrone Verarbeitung und effiziente Datenbankabfragen umsetzen.",
                "Kosten- und Kapazit√§tsmanagement f√ºr Cloud-Ressourcen kontinuierlich optimieren."],
                {"Cloud Performance-Tools": ["K6", "AWS CloudWatch"]}
            )

        if availability == "Ja" and environment == "On-Premise":
            display_test_method(
                "Performance-Tests",
                "Performance-Tests f√ºr On-Premise-Umgebungen bewerten die Systemleistung, Skalierbarkeit und Stabilit√§t unter verschiedenen Lastbedingungen. "
                "Da On-Premise-Systeme oft feste Hardware-Ressourcen nutzen, sind gezielte Optimierungsma√ünahmen notwendig, um Engp√§sse fr√ºhzeitig zu identifizieren.",
                ["Langsame Antwortzeiten bei hoher Last aufgrund begrenzter Hardware-Ressourcen.",
                "Eingeschr√§nkte Skalierbarkeit, da zus√§tzliche Hardware-Investitionen notwendig sind.",
                "Netzwerkengp√§sse oder hohe Latenzen durch unzureichende Bandbreite oder veraltete Infrastruktur.",
                "Unzureichende √úberwachung, wodurch Performance-Probleme erst sp√§t erkannt werden.",
                "Fehlende Kapazit√§tsplanung, die zu √úberlastung oder ineffizienter Ressourcennutzung f√ºhrt."],
                ["Regelm√§√üige Lasttests durchf√ºhren, um Engp√§sse fr√ºhzeitig zu identifizieren und Optimierungspotenziale aufzudecken.",
                "Netzwerk- und Infrastruktur-√úberwachung einrichten, um Engp√§sse in Echtzeit zu erkennen.",
                "Kapazit√§tsplanung durch historische Performance-Daten optimieren, um Wachstum fr√ºhzeitig zu ber√ºcksichtigen.",
                "Caching und Load-Balancing-Techniken nutzen, um die Effizienz der Infrastruktur zu maximieren.",
                "Proaktive Wartung und regelm√§√üige Performance-Analysen durchf√ºhren, um Systemausf√§lle zu vermeiden."],
                {"Performance-Tools": ["JMeter", "Grafana"]}
            )

        # API-ABH√ÑNGIGKEIT
        if high_api_dependence == "Ja":
            display_test_method(
                "API-Tests",
                "API-Tests stellen sicher, dass API-Schnittstellen stabil, zuverl√§ssig und performant sind. "
                "Da moderne Systeme stark auf APIs angewiesen sind, m√ºssen √Ñnderungen sorgf√§ltig getestet werden, um Integrationsprobleme zu vermeiden.",
                ["API-√Ñnderungen brechen bestehende Integrationen, wenn Abw√§rtskompatibilit√§t nicht gew√§hrleistet ist.",
                "Unklare oder fehlende API-Spezifikationen, die zu Missverst√§ndnissen und Implementierungsfehlern f√ºhren.",
                "Inkonsistente Antwortzeiten oder Performance-Schwankungen unter Last.",
                "Fehlende Sicherheitsma√ünahmen, wie unzureichende Authentifizierung oder unverschl√ºsselte Kommunikation.",
                "Unzureichende Fehlerbehandlung, die zu unerwarteten Systemverhalten oder Abst√ºrzen f√ºhren kann."],
                ["API-Tests in die CI/CD-Pipeline integrieren, um Probleme fr√ºhzeitig zu erkennen.",
                "Mocking f√ºr API-Tests nutzen, um externe Abh√§ngigkeiten zu minimieren und isolierte Tests zu erm√∂glichen.",
                "Contract-Testing einsetzen, um sicherzustellen, dass APIs erwartungsgem√§√üe Antworten liefern.",
                "Last- und Performance-Tests f√ºr APIs durchf√ºhren, um Stabilit√§t bei hohem Traffic zu gew√§hrleisten.",
                "Security-Tests f√ºr API-Endpunkte implementieren, um Schwachstellen wie Injection-Angriffe oder unsichere Authentifizierung zu vermeiden."],
                {"API-Testing": ["SoapUI", "Postman", "Rest-Assured"]}
            )

        # DEPLOYMENT-FREQUENZ
        if deployment_frequency in ["T√§glich", "W√∂chentlich"]:
            display_test_method(
                "Statische Code-Analyse",
                "Die statische Code-Analyse √ºberpr√ºft den Quellcode automatisiert auf Fehler, Sicherheitsl√ºcken und Code-Smells, "
                "ohne dass der Code ausgef√ºhrt werden muss. Sie ist besonders bei h√§ufigen Deployments essenziell, um die Codequalit√§t "
                "kontinuierlich sicherzustellen und technische Schulden zu minimieren.",
                ["Fehler oder Sicherheitsl√ºcken werden erst sp√§t erkannt, wenn der Code bereits produktiv ist.",
                "Unn√∂tige technische Schulden entstehen durch nicht standardkonforme oder ineffiziente Implementierungen.",
                "Inkonsistente Code-Qualit√§t innerhalb des Teams f√ºhrt zu schlechter Wartbarkeit.",
                "Fehlende Sicherheitspr√ºfungen im Code k√∂nnen zu potenziellen Schwachstellen f√ºhren.",
                "Versto√ü gegen Coding-Guidelines oder Best Practices, was langfristig die Software-Qualit√§t beeintr√§chtigt."],
                ["Statische Code-Analysen in den Build-Prozess integrieren, um fr√ºhzeitige Erkennung von Fehlern zu erm√∂glichen.",
                "Regelm√§√üige Code-Reviews durchf√ºhren, um manuelle Kontrolle mit automatisierten Checks zu kombinieren.",
                "Security-Scans f√ºr Code in CI/CD-Pipelines einbinden, um Schwachstellen direkt zu identifizieren.",
                "Automatische Durchsetzung von Coding-Guidelines nutzen, um einheitlichen Code-Stil sicherzustellen.",
                "Ergebnisse aus der Code-Analyse in regelm√§√üigen Entwickler-Meetings besprechen, um kontinuierliche Verbesserungen zu f√∂rdern."],
                {"Code-Analyse-Tools": ["SonarQube", "Checkmarx"]}
            )

        display_test_method(
            "User Acceptance Tests (UAT)",
            "User Acceptance Tests (UAT) stellen sicher, dass das System die funktionalen und nicht-funktionalen Anforderungen der Endnutzer erf√ºllt. "
            "Sie sind entscheidend, um sicherzustellen, dass das System praxistauglich ist und vor der produktiven Einf√ºhrung validiert wird.",
            ["Das System erf√ºllt die Anforderungen der Nutzer nicht, weil gesch√§ftskritische Prozesse nicht realit√§tsnah getestet wurden.",
            "Unverst√§ndliche oder nicht intuitive Bedienung f√ºhrt zu einer schlechten Benutzerakzeptanz.",
            "Fehlende oder unklare Abnahmekriterien erschweren eine objektive Bewertung der Testergebnisse.",
            "Unzureichende Testabdeckung, da nicht alle relevanten Nutzungsszenarien ber√ºcksichtigt wurden.",
            "Kommunikationsprobleme zwischen Entwicklern und Fachanwendern f√ºhren zu Missverst√§ndnissen."],
            ["Echte Endnutzer in den Testprozess einbinden, um praxisnahe Szenarien zu validieren.",
            "Klar definierte Abnahmekriterien und Testf√§lle formulieren, um objektive Ergebnisse sicherzustellen.",
            "Fr√ºhzeitige Prototypen oder Beta-Versionen bereitstellen, um fr√ºhzeitig Feedback aus der Praxis zu erhalten.",
            "Exploratives Testen zulassen, um unvorhergesehene Probleme aufzudecken.",
            "Testdokumentation nutzen, um Nachvollziehbarkeit und Vergleichbarkeit der Ergebnisse zu gew√§hrleisten."],
            {"Dokumentation": ["Jira", "Confluence"]}
        )

        display_test_method(
            "End-to-End-Tests",
            "End-to-End-Tests (E2E-Tests) stellen sicher, dass das gesamte System, von Frontend √ºber Backend bis zur Datenbank, "
            "in einer realistischen Umgebung einwandfrei funktioniert. Diese Tests sind essenziell, um sicherzustellen, dass alle "
            "Systemkomponenten korrekt miteinander interagieren und komplexe Benutzerworkflows stabil ablaufen.",
            ["Unstimmigkeiten zwischen Backend und Frontend f√ºhren zu unerwartetem Verhalten oder fehlerhaften Datenanzeigen.",
            "Fehler durch Dateninkonsistenzen zwischen verschiedenen Systemkomponenten, die nicht synchronisiert sind.",
            "Nicht getestete Schnittstellen verursachen Integrationsprobleme bei der Kommunikation zwischen Services.",
            "Skalierungsprobleme, die in isolierten Tests nicht sichtbar werden, treten in realen Nutzungsszenarien auf.",
            "Testf√§lle sind schwer wartbar oder instabil, wenn sie nicht sinnvoll automatisiert werden."],
            ["Tests unter produktionsnahen Bedingungen durchf√ºhren, um realistische Szenarien abzubilden.",
            "Komplexe Benutzerworkflows testen, um sicherzustellen, dass alle Schritte korrekt funktionieren.",
            "Automatisierung gezielt einsetzen, insbesondere f√ºr wiederholbare Testf√§lle mit hohem Mehrwert.",
            "Datenbank- und API-Tests in die End-to-End-Tests integrieren, um Datenfluss und Konsistenz sicherzustellen.",
            "Parallele Testausf√ºhrung nutzen, um die Laufzeit von umfangreichen E2E-Tests zu reduzieren."],
            {"Testautomatisierung": ["Selenium", "Playwright", "Cypress"]}
        )

output =output = BytesIO()
output = BytesIO()
with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
    workbook = writer.book
    worksheet = workbook.add_worksheet("Testmethoden")
    writer.sheets["Testmethoden"] = worksheet

    # Formatierung f√ºr besseren Export
    wrap_format = workbook.add_format({'text_wrap': True, 'valign': 'top'})  # Mehrzeilig & oben ausgerichtet
    bold_format = workbook.add_format({'bold': True, 'text_wrap': True, 'valign': 'top'})  # Mehrzeilig mit Fettschrift

    # System-/Service-Name & Beschreibung platzieren
    worksheet.write(0, 0, "System-/Service-Name:", bold_format)
    worksheet.write(0, 1, system_name, wrap_format)
    worksheet.write(1, 0, "Beschreibung:", bold_format)
    worksheet.write(1, 1, system_description, wrap_format)

    # Testmethoden-√úbersicht (Falls keine Empfehlungen existieren, wird das verhindert)
    if test_recommendations:
        test_data = {"": ["Beschreibung", "H√§ufige Probleme", "Best Practices", "Eingesetzte Tools"]}

        for rec in test_recommendations:
            test_name = rec.get("Testmethode", "Unbenannte Methode")
            test_data[test_name] = [
                rec.get("Beschreibung", ""),
                "\n".join(rec.get("H√§ufige Probleme", "").split(". ")),  # Automatischer Umbruch nach Punkten
                "\n".join(rec.get("Best Practices", "").split(". ")),
                rec.get("Eingesetzte Tools", "")
            ]

        df_tests = pd.DataFrame.from_dict(test_data, orient="index").transpose()

        # Testmethoden ab Zeile 4 einf√ºgen
        df_tests.to_excel(writer, sheet_name="Testmethoden", index=False, startrow=3, startcol=0)

        # **Spaltenbreite begrenzen (max 50 Zeichen)**
        for i, col in enumerate(df_tests.columns):
            worksheet.set_column(i, i, 50, wrap_format)  # Max. 50 Zeichen Breite

        # **Zeilenh√∂he f√ºr bessere Lesbarkeit**
        worksheet.set_row(4, 50, wrap_format)  # Zeilenh√∂he f√ºr "Beschreibung" erh√∂hen
        for row_num in range(5, len(df_tests) + 5):
            worksheet.set_row(row_num, 30, wrap_format)  # Restliche Zeilen auch anpassen

output.seek(0)

# Download-Button f√ºr die Excel-Datei
if test_recommendations:
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    file_name = f"Testmethoden_Empfehlung_{timestamp}.xlsx"

    st.download_button(
        label="Als Excel herunterladen",
        data=output,
        file_name=file_name,
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )
